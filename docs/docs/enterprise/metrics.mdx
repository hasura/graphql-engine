---
sidebar_label: Metrics via Prometheus
description: Metrics via Prometheus for Hasura Enterprise Edition
title: 'Enterprise Edition: Metrics via Prometheus'
keywords:
  - hasura
  - docs
  - enterprise
sidebar_position: 4
---

import ProductBadge from '@site/src/components/ProductBadge';

# Metrics via Prometheus

<ProductBadge self />

## Enable metrics endpoint

By default the Prometheus metrics endpoint is disabled. To enable Prometheus metrics, configure the environment variable
below:

```bash
HASURA_GRAPHQL_ENABLED_APIS=metadata,graphql,config,metrics
```

Secure the Prometheus metrics endpoint with a secret:

```bash
HASURA_GRAPHQL_METRICS_SECRET=<secret>
```

```bash
curl 'http://127.0.0.1:8080/v1/metrics' -H 'Authorization: Bearer <secret>'
```

:::info Configure a secret

The metrics endpoint should be configured with a secret to prevent misuse and should not be exposed over the internet.

:::

:::tip High-cardinality Labels

Starting in `v2.26.0`, Hasura GraphQL Engine exposes metrics with high-cardinality labels by default.

You can disable
[the cardinality of labels for metrics](/deployment/graphql-engine-flags/reference.mdx#enable-high-cardinality-labels-for-metrics)
if you are experiencing high memory usage, which can be due to a large number of labels in the metrics (typically more
than 10000).

:::

## Metrics exported

The following metrics are exported by Hasura GraphQL Engine:

### Hasura active subscriptions

Current number of active subscriptions, representing the subscription load on the server.

|        |                                                                                            |
| ------ | ------------------------------------------------------------------------------------------ |
| Name   | `hasura_active_subscriptions`                                                              |
| Type   | Gauge                                                                                      |
| Labels | `subscription_kind`: streaming \| live-query, `operation_name`, `parameterized_query_hash` |

### Hasura active subscription pollers

Current number of active subscription pollers. A subscription poller
[multiplexes](https://github.com/hasura/graphql-engine/blob/master/architecture/live-queries.md#idea-3-batch-multiple-live-queries-into-one-sql-query)
similar subscriptions together. The value of this metric should be proportional to the number of uniquely parameterized
subscriptions (i.e., subscriptions with the same selection set, but with different input arguments and session variables
are multiplexed on the same poller). If this metric is high then it may be an indication that there are too many
uniquely parameterized subscriptions which could be optimized for better performance.

|        |                                              |
| ------ | -------------------------------------------- |
| Name   | `hasura_active_subscription_pollers`         |
| Type   | Gauge                                        |
| Labels | `subscription_kind`: streaming \| live-query |

### Hasura active subscription pollers in error state

Current number of active subscription pollers that are in the error state. A subscription poller
[multiplexes](https://github.com/hasura/graphql-engine/blob/master/architecture/live-queries.md#idea-3-batch-multiple-live-queries-into-one-sql-query)
similar subscriptions together. A non-zero value of this metric indicates that there are runtime errors in atleast one
of the subscription pollers that are running in Hasura. In most of the cases, runtime errors in subscriptions are caused
due to the changes at the data model layer and fixing the issue at the data model layer should automatically fix the
runtime errors.

|        |                                                     |
| ------ | --------------------------------------------------- |
| Name   | `hasura_active_subscription_pollers_in_error_state` |
| Type   | Gauge                                               |
| Labels | `subscription_kind`: streaming \| live-query        |

### Hasura cache request count

Tracks cache hit and miss requests, which helps in monitoring and optimizing cache utilization. You can read more about this [here](/caching/caching-metrics.mdx).

|        |                              |
| ------ | ---------------------------- |
| Name   | `hasura_cache_request_count` |
| Type   | Counter                      |
| Labels | `status`: hit \| miss        |

### Hasura cron events invocation total

Total number of cron events invoked, representing the number of invocations made for cron events.

|        |                                       |
| ------ | ------------------------------------- |
| Name   | `hasura_cron_events_invocation_total` |
| Type   | Counter                               |
| Labels | `status`: success \| failed           |

### Hasura cron events processed total

Total number of cron events processed, representing the number of invocations made for cron events. Compare this to
`hasura_cron_events_invocation_total`. A high difference between the two metrics indicates high failure rate of the cron
webhook.

|        |                                      |
| ------ | ------------------------------------ |
| Name   | `hasura_cron_events_processed_total` |
| Type   | Counter                              |
| Labels | `status`: success \| failed          |

### Hasura event fetch time per batch

Latency of fetching a batch of events. A higher metric indicates slower polling of events from the database, you should
consider looking into the performance of your database.

|        |                                                                                            |
| ------ | ------------------------------------------------------------------------------------------ |
| Name   | `hasura_event_fetch_time_per_batch_seconds`                                                |
| Type   | Histogram<br /><br />Buckets: 0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10 |
| Labels | none                                                                                       |

### Hasura event invocations total

Total number of events invoked. Represents the Event Trigger webhook HTTP requests made.

|        |                                                            |
| ------ | ---------------------------------------------------------- |
| Name   | `hasura_event_invocations_total`                           |
| Type   | Counter                                                    |
| Labels | `status`: success \| failed, `source_name`, `trigger_name` |

### Hasura event processed total

Total number of events processed. Represents the Event Trigger egress.

|        |                                                            |
| ------ | ---------------------------------------------------------- |
| Name   | `hasura_event_processed_total`                             |
| Type   | Counter                                                    |
| Labels | `status`: success \| failed, `source_name`, `trigger_name` |

### Hasura event processing time

The time taken for an event to be delivered since it's been created (if first attempt) or retried (after first attempt).
This metric can be considered as the end-to-end processing time for an event.

|        |                                                                       |
| ------ | --------------------------------------------------------------------- |
| Name   | `hasura_event_processing_time_seconds`                                |
| Type   | Histogram<br /><br />Buckets: 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100 |
| Labels | `source_name`, `trigger_name`                                         |

### Hasura event queue time

Queue time for an event already in the processing queue. More events in a higher bucket implies slow processing. In this
case, you can consider increasing the
[HTTP pool size](/deployment/graphql-engine-flags/reference.mdx/#events-http-pool-size) or optimizing the webhook
server.

|        |                                                                       |
| ------ | --------------------------------------------------------------------- |
| Name   | `hasura_event_queue_time_seconds`                                     |
| Type   | Histogram<br /><br />Buckets: 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100 |
| Labels | `source_name`, `trigger_name`                                         |

### Hasura event trigger HTTP workers

Current number of active Event Trigger HTTP workers. Compare this number to the
[HTTP pool size](/deployment/graphql-engine-flags/reference.mdx/#events-http-pool-size). Consider increasing it if the
metric is near the current configured value.

|        |                                     |
| ------ | ----------------------------------- |
| Name   | `hasura_event_trigger_http_workers` |
| Type   | Gauge                               |
| Labels | none                                |

### Hasura event webhook processing time

The time between when an HTTP worker picks an event for delivery to the time its response is updated in the DB. A higher
processing time indicates slow webhook, you should try to optimize the event webhook.

|        |                                                              |
| ------ | ------------------------------------------------------------ |
| Name   | `hasura_event_webhook_processing_time_seconds`               |
| Type   | Histogram<br /><br />Buckets: 0.01, 0.03, 0.1, 0.3, 1, 3, 10 |
| Labels | `source_name`, `trigger_name`                                |

### Hasura events fetched per batch

Number of events fetched in a batch. This number should be equal to the
[events fetch batch size](/deployment/graphql-engine-flags/reference.mdx/#events-fetch-batch-size) if there are any
pending events, else this should be 0.

|        |                                   |
| ------ | --------------------------------- |
| Name   | `hasura_events_fetched_per_batch` |
| Type   | Gauge                             |
| Labels | none                              |

### Hasura GraphQL execution time seconds

Execution time of successful GraphQL requests (excluding subscriptions). If more requests are falling in the higher
buckets, you should consider [tuning the performance](/deployment/performance-tuning.mdx).

|        |                                                                |
| ------ | -------------------------------------------------------------- |
| Name   | `hasura_graphql_execution_time_seconds`                        |
| Type   | Histogram<br /><br />Buckets: 0.01, 0.03, 0.1, 0.3, 1, 3, 10   |
| Labels | `operation_type`: query \| mutation \| subscription \| unknown |

### Hasura GraphQL requests total

Number of GraphQL requests received, representing the GraphQL query/mutation traffic on the server.

|        |                                                                |
| ------ | -------------------------------------------------------------- |
| Name   | `hasura_graphql_requests_total`                                |
| Type   | Counter                                                        |
| Labels | `operation_type`: query \| mutation \| subscription \| unknown |

The `unknown` operation type will be returned for queries that fail authorization, parsing, or certain validations. The
`response_status` label will be `success` for successful requests and `failed` for failed requests.

### Hasura HTTP connections

Current number of active HTTP connections (excluding WebSocket connections), representing the HTTP load on the server.

|        |                           |
| ------ | ------------------------- |
| Name   | `hasura_http_connections` |
| Type   | Gauge                     |
| Labels | none                      |

### Hasura one-off events invocation total

Total number of one-off events invoked, representing the number of invocations made for one-off events.

|        |                                         |
| ------ | --------------------------------------- |
| Name   | `hasura_oneoff_events_invocation_total` |
| Type   | Counter                                 |
| Labels | `status`: success \| failed             |

### Hasura one-off events processed total

Total number of one-off events processed, representing the number of invocations made for one-off events. Compare this
to `hasura_oneoff_events_invocation_total`. A high difference between the two metrics indicates high failure rate of the
one-off webhook.

|        |                                        |
| ------ | -------------------------------------- |
| Name   | `hasura_oneoff_events_processed_total` |
| Type   | Counter                                |
| Labels | `status`: success \| failed            |

### Hasura postgres connections

Current number of active PostgreSQL connections. Compare this to
[pool settings](/api-reference/syntax-defs.mdx/#pgpoolsettings).

|        |                                                                                                                                                                                   |
| ------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name   | `hasura_postgres_connections`                                                                                                                                                     |
| Type   | Gauge                                                                                                                                                                             |
| Labels | `source_name`: name of the database<br />`conn_info`: connection url string (password omitted) or name of the connection url environment variable<br />`role`: primary \| replica |

### Hasura source health

Health check status of a particular data source, corresponding to the output of
`/healthz/sources`, with possible values 0 through 3 indicating, respectively:
OK, TIMEOUT, FAILED, ERROR. See the [Source Health Check API Reference](/api-reference/source-health.mdx)
for details.

|        |                                                                                                                                                                                   |
| ------ | -------------------------------------- |
| Name   | `hasura_source_health`                 |
| Type   | Gauge                                  |
| Labels | `source_name`: name of the database    |

### Hasura subscription database execution time

The time taken to run the subscription's multiplexed query in the database for a single batch.

A subscription poller
[multiplexes](https://github.com/hasura/graphql-engine/blob/master/architecture/live-queries.md#idea-3-batch-multiple-live-queries-into-one-sql-query)
similar subscriptions together. During every run (every 1 second by default), the poller splits the different variables
for the multiplexed query into batches (by default 100) and execute the batches. This metric observes the time taken for
each batch to execute on the database.

If this metric is high, then it may be an indication that the database is not performing as expected, you should
consider investigating the subscription query and see if indexes can help improve performance.

|        |                                                                                            |
| ------ | ------------------------------------------------------------------------------------------ |
| Name   | `hasura_subscription_db_execution_time_seconds`                                            |
| Type   | Histogram<br /><br />Buckets: 0.000001, 0.0001, 0.01, 0.1, 0.3, 1, 3, 10, 30, 100          |
| Labels | `subscription_kind`: streaming \| live-query, `operation_name`, `parameterized_query_hash` |

### Hasura subscription total time

The time taken to complete running of one subscription poller.

A subscription poller
[multiplexes](https://github.com/hasura/graphql-engine/blob/master/architecture/live-queries.md#idea-3-batch-multiple-live-queries-into-one-sql-query)
similar subscriptions together. This subscription poller runs every 1 second by default and queries the database with
the multiplexed query to fetch the latest data. In a polling instance, the poller not only queries the database but does
other operations like splitting similar queries into batches (by default 100) before fetching their data from the
database, etc. **This metric is the total time taken to complete all the operations in a single poll.**

If the value of this metric is high, then it may be an indication that the multiplexed query is taking longer to execute
in the database, verify with
[`hasura_subscription_db_execution_time_seconds`](/enterprise/metrics.mdx/#hasura-subscription-database-execution-time)
metric.

In a single poll, the subscription poller splits the different variables for the multiplexed query into batches (by
default 100) and executes the batches. We use the `hasura_subscription_db_execution_time_seconds` metric to observe the
time taken for each batch to execute on the database. This means for a single poll there can be multiple values for
`hasura_subscription_db_execution_time_seconds` metric.

Let's look at an example to understand these metrics better:

Say we have 650 subscriptions with the same selection set but different input arguments. These 650 subscriptions will be
grouped to form one multiplexed query. A single poller would be created to run this multiplexed query. This poller will
run every 1 second.

The default batch size in hasura is 100, so the 650 subscriptions will be split into 7 batches for execution during a
single poll.

During a single poll:

- Batch 1: `hasura_subscription_db_execution_time_seconds` = 0.002 seconds
- Batch 2: `hasura_subscription_db_execution_time_seconds` = 0.001 seconds
- Batch 3: `hasura_subscription_db_execution_time_seconds` = 0.003 seconds
- Batch 4: `hasura_subscription_db_execution_time_seconds` = 0.001 seconds
- Batch 5: `hasura_subscription_db_execution_time_seconds` = 0.002 seconds
- Batch 6: `hasura_subscription_db_execution_time_seconds` = 0.001 seconds
- Batch 7: `hasura_subscription_db_execution_time_seconds` = 0.002 seconds

The `hasura_subscription_total_time_seconds` would be sum of all the database execution times shown in the batches, plus
some extra process time for other tasks the poller does during a single poll. In this case, it would be approximately
0.013 seconds.

|        |                                                                                            |
| ------ | ------------------------------------------------------------------------------------------ |
| Name   | `hasura_subscription_total_time_seconds`                                                   |
| Type   | Histogram<br /><br />Buckets: 0.000001, 0.0001, 0.01, 0.1, 0.3, 1, 3, 10, 30, 100          |
| Labels | `subscription_kind`: streaming \| live-query, `operation_name`, `parameterized_query_hash` |

### Hasura WebSocket connections

Current number of active WebSocket connections, representing the WebSocket load on the server.

|        |                                |
| ------ | ------------------------------ |
| Name   | `hasura_websocket_connections` |
| Type   | Gauge                          |
| Labels | none                           |

:::info GraphQL request execution time

- Uses wall-clock time, so it includes time spent waiting on I/O.
- Includes authorization, parsing, validation, planning, and execution (calls to databases, Remote Schemas).

:::
